{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSAM On The Fly\n",
    "--\n",
    "\n",
    "Calculate RSAM 'on the fly' for a single channel.\n",
    "\n",
    "The RSAM interval is fixed at 10 mins, the most commonly used interval. \n",
    "\n",
    "The intention is that this notebook is used to quickly calculate RSAM data for a seismic stream of interest. All seismic waveform data are read into memory at once, so specifying too long a date range will make this overly slow. This notebook is therefore _not_ intended to be used to calculate RSAM values for long periods of time.\n",
    "\n",
    "The RSAM data are simply plotted to check you have retrieved the data you want, and output as a CSV file that can be used for further analysis.\n",
    "\n",
    "The CSV file format is\n",
    "\n",
    "`,rsam\n",
    "2018-05-08T00:00:00,18.452843689933633\n",
    "2018-05-08T00:10:00,16.452106331639985\n",
    "2018-05-08T00:20:00,16.536061488147663`\n",
    "\n",
    "The date-time is ISO8601 format. The RSAM unit is nanometres/second. No attempt is made to limit the number of significant digits in the RSAM values\n",
    "\n",
    "**This is not intended to be a siphisticated notebook, but a tool to fill a gap. No attempt has been made to set up nice input, or to hide code cells.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import obspy\n",
    "from obspy.core import read, Trace, Stream, UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit this cell to specify stream, date range, and filters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = 'HBAZ.10.EHZ.NZ'\n",
    "\n",
    "#dates are inclusive, and complete days\n",
    "date1 = '2020-03-15'\n",
    "date2 = '2020-03-29'\n",
    "\n",
    "#filter options are 'none', 'lp', 'hp', 'bp'\n",
    "\n",
    "# filtertype = 'none'\n",
    "\n",
    "filtertype = 'bp'\n",
    "f1 = 1.0\n",
    "f2 = 4.0\n",
    "\n",
    "# filtertype = 'hp'\n",
    "# f = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GeoNet's FDSN web servers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_client = 'http://service.geonet.org.nz'\n",
    "nrt_client = 'http://service-nrt.geonet.org.nz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get a stream from both FDSN clients\n",
    "def waveboth(start, end, net, stn, loc, cmp):\n",
    "    global st\n",
    "    try:\n",
    "        client = Client(arc_client)\n",
    "        starc = client.get_waveforms(net, stn, loc, cmp, start, end, attach_response=True)\n",
    "        print('arc client successful')\n",
    "    except:\n",
    "        print('arc client not successful')\n",
    "        starc = Stream()\n",
    "    try:\n",
    "        client = Client(nrt_client)\n",
    "        stnrt = client.get_waveforms(net, stn, loc, cmp, start, end, attach_response=True)\n",
    "        print ('nrt client successful')\n",
    "    except:\n",
    "        print('nrt client not successful')\n",
    "        stnrt = Stream()\n",
    "  \n",
    "    st = starc + stnrt\n",
    "    st.merge(fill_value = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare dates and stream information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dt.datetime.strptime(date1, '%Y-%m-%d')\n",
    "d2 = dt.datetime.strptime(date2, '%Y-%m-%d')\n",
    "\n",
    "site, loc, cmp, net = str.split(stream, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve seismic time series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = UTCDateTime(date1)\n",
    "end = UTCDateTime(date2) + 86400\n",
    "\n",
    "waveboth(start, end, net, site, loc, cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare seismic time series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.remove_sensitivity()\n",
    "st.merge(fill_value = 'interpolate')    #in case stream has more than one trace\n",
    "tr = st[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtertype == 'lp':\n",
    "    tr.filter('lowpass', freq=f, corners=4, zerophase=False)\n",
    "elif filtertype == 'hp':\n",
    "    tr.filter('highpass', freq=f, corners=4, zerophase=False)\n",
    "elif filtertype == 'bp':\n",
    "    tr.filter('bandpass', freqmin=f1, freqmax=f2, corners=4, zerophase=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RSAM calculation, values put into a Pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise dataframe\n",
    "rsam = pd.DataFrame()\n",
    "\n",
    "t = tr.stats.starttime\n",
    "index = 0\n",
    "#loop through data in 600sec (10 min) blocks\n",
    "while t < tr.stats.endtime:\n",
    "    tr10m = tr.slice(t, t + 600)\n",
    "    duration = tr10m.stats.npts * tr10m.stats.delta\n",
    "    if duration >= 500:\n",
    "        if duration < 600:\n",
    "            tr10m = tr.slice(tr.stats.endtime - 600, tr.stats.endtime) \n",
    "        #detrend and filter\n",
    "        #tr10m.detrend(type='constant')\n",
    "    \n",
    "        absolute = np.absolute(tr10m.data) #absolute value\n",
    "        tr10m.data = absolute #assign back to trace\n",
    "        mean = tr10m.data.mean()\n",
    "        mean = mean / 1e-9 #convert to nanometres so dealing with whole numbers\n",
    "        data = {'datetime':t, 'rsam':mean}\n",
    "        data = {'rsam':mean}\n",
    "        tstr = pd.to_datetime(UTCDateTime.strftime(t, '%Y-%m-%dT%H:%M:%S'))\n",
    "        df = pd.DataFrame(data, index=[tstr])\n",
    "        rsam = rsam.append(df)\n",
    "        index += 1\n",
    "    t += 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = rsam.plot()\n",
    "fig = rs.get_figure()\n",
    "fig.savefig('rsam_onthefly.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output to CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rsam output file name\n",
    "if filtertype == 'none':\n",
    "    rsfile = 'rsam_'+stream+'_'+date1+'-'+date2+'.csv'\n",
    "elif (filtertype == 'lp') | (filtertype == 'hp'):\n",
    "    strf = '%.2f' %f\n",
    "    rsfile = 'rsam_'+stream+'_'+date1+'-'+date2+'_'+filtertype+'_'+strf+'.csv'\n",
    "elif filtertype == 'bp':\n",
    "    strf1 = '%.2f' %f1\n",
    "    strf2 = '%.2f' %f2\n",
    "    rsfile = 'rsam_'+stream+'_'+date1+'-'+date2+'_'+filtertype+'_'+strf1+'-'+strf2+'.csv'\n",
    "\n",
    "rsam.to_csv(rsfile, date_format='%Y-%m-%dT%H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
