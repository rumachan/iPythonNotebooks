{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raoul Island Lake Monitoring Data - Calculation and Presentation of Daily Mean Data\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Raoul Island, the temperature and level of Green Lake and the temperature of Marker Bay pool are measured. Measurements are digitised with a Quanterra Q330 at a sample rate of 1 sample per second. For plotting and examination of these data over time periods of several years, a sample rate of 1 sample per second is too high for the slowly changing temperatures and lake level.\n",
    "\n",
    "The raw data are stored as mini-seed files as part of GeoNet's seismic data archive. These data can be accessed using GeoNet's FDSN web servers http://www.geonet.org.nz/data/tools/FDSN. Response information can be retrieved with the raw data, which allows raw observations to be converted to units of degrees celcius and metres, respectively.\n",
    "\n",
    "Running this python notebook will first update the daily mean data files (if required), and then make long-term plots of the data. The daily mean files are stored on disk (as CSV files) and can be copied for use elsewhere.\n",
    "\n",
    "If a waveform data file is unavailable, or cannot be read, the 'value' and 'error' for that day will be set to NaN (https://en.wikipedia.org/wiki/NaN). This means that data plots will automatically 'break' at that point.\n",
    "\n",
    "Plots show:\n",
    "- daily mean data as a solid line\n",
    "- +/- two standard deviations around the mean temperature as a semi-opaque band\n",
    "\n",
    "For short-term changes, the Platform team provides frequently updating plots using the full 1 sample per second data. These plots are available on the GeoNet wiki:\n",
    "- http://images.geonet.org.nz/volcano/ki/glkz/40/drum.png\n",
    "- http://images.geonet.org.nz/volcano/ki/glkz/80/drum.png\n",
    "- http://images.geonet.org.nz/volcano/ki/glkz/81/drum.png.\n",
    "\n",
    "Because of the way GeoNet's FDSN web servers are set up http://www.geonet.org.nz/data/tools/FDSN, this script does not create daily mean data upto the current day, but stops 10 days ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from obspy.core import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fdsn client\n",
    "client = Client(\"http://service.geonet.org.nz\")\n",
    "#this client contains only data 8 days old and older, see http://www.geonet.org.nz/data/tools/FDSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daywave(date, net, sta, loc, cmp):\n",
    "  global st\n",
    "  time = UTCDateTime(date)\n",
    "  st = client.get_waveforms(net, sta, loc, cmp, time, time + 86400, attach_response=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#channel data for fdsn\n",
    "net = 'NZ'\n",
    "sta = 'GLKZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get data upto how many days before now\n",
    "ndays = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#channel specific parameters\n",
    "chan = [{'loc':'80', 'cmp':'LKO', 'fname':'glt.csv', 'subject':'green lake temperature'},\n",
    "        {'loc':'81', 'cmp':'LKO', 'fname':'mbt.csv', 'subject':'marker bay temperature'},\n",
    "        {'loc':'40', 'cmp':'LTH', 'fname':'gll.csv', 'subject':'green lake level'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#column names\n",
    "names = ['date', 'value', 'error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update daily average data\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each channel:\n",
    "- read the existing data from a CSV file\n",
    "- find out which data need to be processed\n",
    "- process the new data, calculating a daily mean value and standard deviation (error)\n",
    "- append the new data to the existing\n",
    "- write a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ch in chan:   \n",
    "    #set variables\n",
    "    cmp = ch['cmp']\n",
    "    fname = ch['fname']\n",
    "    loc = ch['loc']\n",
    "    subject = ch['subject']\n",
    "    print fname, cmp, loc, subject\n",
    "    #read in existing data\n",
    "    df = pd.read_csv(fname, parse_dates=True, names=names, index_col=0, skiprows=1)#, infer_datetime_format=True)\n",
    "    \n",
    "    #find first date to process\n",
    "    dt1 = df.index[-1] + pd.to_timedelta(1, unit='D')\n",
    "    dt1str = dt1.strftime('%Y-%m-%d')\n",
    "    print 'first date to process '+dt1str\n",
    "        \n",
    "    #find last date to process\n",
    "    dt2 = UTCDateTime() - (ndays * 86400)\n",
    "    dt2str = dt2.date.strftime('%Y-%m-%d')\n",
    "    print 'last date to process '+dt2str\n",
    "          \n",
    "    for date in pd.date_range(start=dt1str, end=dt2str, freq='D'):\n",
    "        try:\n",
    "            daywave(date, net, sta, loc, cmp)\n",
    "            st.remove_sensitivity()\n",
    "            st.merge(fill_value = 'interpolate')\n",
    "            tr = st[0]\n",
    "            mean = tr.data.mean()\n",
    "            std = tr.data.std()\n",
    "        except:\n",
    "            print date.date(), 'retrieve unsuccessful'\n",
    "            mean = float('nan')\n",
    "            std = float('nan')\n",
    "        print date.date(), mean, std\n",
    "        vals = {'date':date.date(), 'value':mean, 'error':std}\n",
    "        vals = {'value':mean, 'error':std}\n",
    "        newrow = pd.DataFrame([vals], columns=vals.keys(), index={pd.to_datetime(date.date())})\n",
    "        df = df.append(newrow, ignore_index=False)\n",
    "    \n",
    "    df.to_csv(fname, columns=['value', 'error'], na_rep='NaN', index=True)\n",
    "    \n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the full data set\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a combined temperature plot for Green Lake and Marker Bay.\n",
    "\n",
    "Make a plots of the water depth above the sensor at Green Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Green Lake and Marker Bay temperatures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the upto date data\n",
    "glt = pd.read_csv('glt.csv', parse_dates=True, index_col=0)\n",
    "mbt = pd.read_csv('mbt.csv', parse_dates=True, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize=(15,5)\n",
    "plt.figure()\n",
    "temps = glt['value'].plot(label='Green Lake', color='green', figsize=figsize)\n",
    "plt.fill_between(glt.index, glt.value-2*glt.error, glt.value+2*glt.error, color='green', alpha=0.3)\n",
    "mbt['value'].plot(ax=temps, label='Marker Bay')\n",
    "plt.fill_between(mbt.index, mbt.value-2*mbt.error, mbt.value+2*mbt.error, color='blue', alpha=0.3)\n",
    "temps.legend(loc='best')\n",
    "temps.set_ylabel('water temperature (degC)')\n",
    "temps.set_title('Green Lake and Marker Bay Temperatures (daily averages)', fontsize=16)\n",
    "plt.xlabel(\"\") #get rid of useless 'date' label\n",
    "plt.savefig('glt_mbt.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Green Lake level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the upto date data\n",
    "gll = pd.read_csv('gll.csv', parse_dates=True, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot y-axis limits, adjust these if large (real) changes occur\n",
    "ylim1 = 0.5\n",
    "ylim2 = 3.5\n",
    "\n",
    "#replace values that are clearly not representative of the water depth with NaN\n",
    "#green lake level data have some issues!\n",
    "#error\n",
    "gll.loc[gll.value < ylim1, 'error'] = float('nan')\n",
    "gll.loc[gll.value > ylim2, 'error'] = float('nan')\n",
    "#value\n",
    "gll.loc[gll.value < ylim1, 'value'] = float('nan')\n",
    "gll.loc[gll.value > ylim2, 'value'] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(15,5)\n",
    "plt.figure()\n",
    "level = gll['value'].plot(color='green', figsize=figsize)\n",
    "plt.fill_between(gll.index, gll.value-2*gll.error, gll.value+2*gll.error, color='green', alpha=0.3)\n",
    "level.set_ylabel('water depth above sensor (m)')\n",
    "level.set_title('Green Lake Level (daily averages)', fontsize=16)\n",
    "level.set_ylim(ylim1,ylim2)\n",
    "plt.xlabel(\"\") #get rid of useless 'date' label\n",
    "plt.savefig('gll.png', dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
